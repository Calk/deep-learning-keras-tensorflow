{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolution Nets for MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Deep Learning models can take quite a bit of time to run, particularly if GPU isn't used. \n",
    "\n",
    "In the interest of time, you could sample a subset of observations (e.g. $1000$) that are a particular number of your choice (e.g. $6$) and $1000$ observations that aren't that particular number (i.e. $\\neq 6$). \n",
    "\n",
    "We will build a model using that and see how it performs on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import the required libraries\n",
    "import numpy as np\n",
    "np.random.seed(1338)\n",
    "\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Dropout, Activation, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "path_to_dataset = \"/home/ubuntu/deep-learning-keras-tensorflow/data/mnist.pkl.gz\"\n",
    "\n",
    "#Load the training and testing data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data(path_to_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "X_test_orig = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols,1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols,1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Seed for reproducibilty\n",
    "np.random.seed(1338)\n",
    "\n",
    "# Test data\n",
    "X_test = X_test.copy()\n",
    "Y = y_test.copy()\n",
    "\n",
    "# Converting the output to binary classification(Six=1,Not Six=0)\n",
    "Y_test = Y == 6\n",
    "Y_test = Y_test.astype(int)\n",
    "\n",
    "# Selecting the 5918 examples where the output is 6\n",
    "X_six = X_train[y_train == 6].copy()\n",
    "Y_six = y_train[y_train == 6].copy()\n",
    "\n",
    "# Selecting the examples where the output is not 6\n",
    "X_not_six = X_train[y_train != 6].copy()\n",
    "Y_not_six = y_train[y_train != 6].copy()\n",
    "\n",
    "# Selecting 6000 random examples from the data that \n",
    "# only contains the data where the output is not 6\n",
    "random_rows = np.random.randint(0,X_six.shape[0],6000)\n",
    "X_not_six = X_not_six[random_rows]\n",
    "Y_not_six = Y_not_six[random_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Appending the data with output as 6 and data with output as <> 6\n",
    "X_train = np.append(X_six,X_not_six)\n",
    "\n",
    "# Reshaping the appended data to appropraite form\n",
    "X_train = X_train.reshape(X_six.shape[0] + X_not_six.shape[0], img_rows, img_cols,1)\n",
    "\n",
    "# Appending the labels and converting the labels to \n",
    "# binary classification(Six=1,Not Six=0)\n",
    "Y_labels = np.append(Y_six,Y_not_six)\n",
    "Y_train = Y_labels == 6 \n",
    "Y_train = Y_train.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11918, 28, 28, 1) (11918,) (10000, 28, 28, 1) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_labels.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Converting the classes to its binary categorical form\n",
    "nb_classes = 2\n",
    "Y_train = np_utils.to_categorical(Y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(Y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Initializing the values for the convolution neural network\n",
    "nb_epoch = 2\n",
    "batch_size = 128\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "nb_pool = 2\n",
    "# convolution kernel size\n",
    "nb_conv = 3\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Step 1: Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                        border_mode='valid',\n",
    "                        input_shape=(img_rows, img_cols,1)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Step 2: Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Step 3: Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11918 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "11918/11918 [==============================] - 4s - loss: 0.3033 - acc: 0.9382 - val_loss: 0.1746 - val_acc: 0.9557\n",
      "Epoch 2/2\n",
      "11918/11918 [==============================] - 3s - loss: 0.1369 - acc: 0.9602 - val_loss: 0.1499 - val_acc: 0.9515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7d29b97e48>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=batch_size, \n",
    "          nb_epoch=nb_epoch,verbose=1,\n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Step 4: Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.149916631544\n",
      "Test accuracy: 0.9515\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the test data    \n",
    "score, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Let's plot our model Predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA50AAABVCAYAAADKf4AOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7d18113e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "slice = 15\n",
    "predicted = model.predict(X_test[:slice]).argmax(-1)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "for i in range(slice):\n",
    "    plt.subplot(1, slice, i+1)\n",
    "    plt.imshow(X_test_orig[i], interpolation='nearest')\n",
    "    plt.text(0, 0, predicted[i], color='black', \n",
    "             bbox=dict(facecolor='white', alpha=1))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Adding more Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                        border_mode='valid',\n",
    "                        input_shape=(img_rows, img_cols,1)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11918 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "11918/11918 [==============================] - 7s - loss: 0.3020 - acc: 0.9326 - val_loss: 0.1210 - val_acc: 0.9703\n",
      "Epoch 2/2\n",
      "11918/11918 [==============================] - 7s - loss: 0.1198 - acc: 0.9637 - val_loss: 0.1133 - val_acc: 0.9622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7cd85af9e8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, \n",
    "          nb_epoch=nb_epoch,verbose=1,\n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.113300963235\n",
      "Test accuracy: 0.9622\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the model on the test data    \n",
    "score, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Adding Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                        border_mode='valid',\n",
    "                        input_shape=(img_rows, img_cols,1)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11918 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "11918/11918 [==============================] - 7s - loss: 0.2821 - acc: 0.9286 - val_loss: 0.2185 - val_acc: 0.9224\n",
      "Epoch 2/2\n",
      "11918/11918 [==============================] - 9s - loss: 0.1220 - acc: 0.9631 - val_loss: 0.0912 - val_acc: 0.9705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7d1812fd30>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, \n",
    "          nb_epoch=nb_epoch,verbose=1,\n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.0912129176855\n",
      "Test accuracy: 0.9705\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the model on the test data    \n",
    "score, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Adding more Convolution Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                        border_mode='valid',\n",
    "                        input_shape=(img_rows, img_cols,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "model.add(Dropout(0.25))\n",
    "    \n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11918 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "11918/11918 [==============================] - 16s - loss: 0.6112 - acc: 0.7496 - val_loss: 0.4618 - val_acc: 0.8888\n",
      "Epoch 2/2\n",
      "11918/11918 [==============================] - 15s - loss: 0.2683 - acc: 0.9168 - val_loss: 0.1485 - val_acc: 0.9562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7cd83b3cc0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, \n",
    "          nb_epoch=nb_epoch,verbose=1,\n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.148507375973\n",
      "Test accuracy: 0.9562\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the model on the test data    \n",
    "score, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "The above code has been written as a function. \n",
    "\n",
    "Change some of the **hyperparameters** and see what happens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Function for constructing the convolution neural network\n",
    "# Feel free to add parameters, if you want\n",
    "\n",
    "def build_model():\n",
    "    \"\"\"\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                        border_mode='valid',\n",
    "                        input_shape=(img_rows, img_cols,1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, Y_train, batch_size=batch_size, \n",
    "              nb_epoch=nb_epoch,verbose=1,\n",
    "              validation_data=(X_test, Y_test))\n",
    "          \n",
    "\n",
    "    #Evaluating the model on the test data    \n",
    "    score, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11918 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "11918/11918 [==============================] - 18s - loss: 0.6337 - acc: 0.7351 - val_loss: 0.5278 - val_acc: 0.8435\n",
      "Epoch 2/2\n",
      "11918/11918 [==============================] - 15s - loss: 0.2991 - acc: 0.9097 - val_loss: 0.1805 - val_acc: 0.9432\n",
      "Test score: 0.180504751903\n",
      "Test accuracy: 0.9432\n",
      "1 loop, best of 1: 38.7 s per loop\n"
     ]
    }
   ],
   "source": [
    "#Timing how long it takes to build the model and test it.\n",
    "%timeit -n1 -r1 build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Batch Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the activations of the previous layer at each batch, i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How to BatchNorm in Keras\n",
    "\n",
    "```python\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "BatchNormalization(epsilon=1e-06, mode=0, \n",
    "                   axis=-1, momentum=0.99, \n",
    "                   weights=None, beta_init='zero', \n",
    "                   gamma_init='one')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11918 samples, validate on 10000 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value batchnormalization_1_running_mean/biased\n\t [[Node: batchnormalization_1_running_mean/biased/read = Identity[T=DT_FLOAT, _class=[\"loc:@batchnormalization_1_running_mean\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batchnormalization_1_running_mean/biased)]]\n\nCaused by op 'batchnormalization_1_running_mean/biased/read', defined at:\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-32-4ae7110b2af1>\", line 7, in <module>\n    model.add(BatchNormalization())\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/keras/models.py\", line 307, in add\n    output_tensor = layer(self.outputs[0])\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/keras/engine/topology.py\", line 511, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/keras/engine/topology.py\", line 569, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/keras/engine/topology.py\", line 150, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/keras/layers/normalization.py\", line 124, in call\n    self.updates = [K.moving_average_update(self.running_mean, mean, self.momentum),\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 288, in moving_average_update\n    variable, value, momentum)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/training/moving_averages.py\", line 70, in assign_moving_average\n    update_delta = _zero_debias(variable, value, decay)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/training/moving_averages.py\", line 177, in _zero_debias\n    trainable=False)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 1024, in get_variable\n    custom_getter=custom_getter)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 850, in get_variable\n    custom_getter=custom_getter)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 346, in get_variable\n    validate_shape=validate_shape)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 331, in _true_getter\n    caching_device=caching_device, validate_shape=validate_shape)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 677, in _get_single_variable\n    expected_shape=shape)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 224, in __init__\n    expected_shape=expected_shape)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 370, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1424, in identity\n    result = _op_def_lib.apply_op(\"Identity\", input=input, name=name)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value batchnormalization_1_running_mean/biased\n\t [[Node: batchnormalization_1_running_mean/biased/read = Identity[T=DT_FLOAT, _class=[\"loc:@batchnormalization_1_running_mean\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batchnormalization_1_running_mean/biased)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value batchnormalization_1_running_mean/biased\n\t [[Node: batchnormalization_1_running_mean/biased/read = Identity[T=DT_FLOAT, _class=[\"loc:@batchnormalization_1_running_mean\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batchnormalization_1_running_mean/biased)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-4ae7110b2af1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m model.fit(X_train, Y_train, batch_size=batch_size, \n\u001b[1;32m     27\u001b[0m           \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m           validation_data=(X_test, Y_test))\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1105\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value batchnormalization_1_running_mean/biased\n\t [[Node: batchnormalization_1_running_mean/biased/read = Identity[T=DT_FLOAT, _class=[\"loc:@batchnormalization_1_running_mean\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batchnormalization_1_running_mean/biased)]]\n\nCaused by op 'batchnormalization_1_running_mean/biased/read', defined at:\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-32-4ae7110b2af1>\", line 7, in <module>\n    model.add(BatchNormalization())\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/keras/models.py\", line 307, in add\n    output_tensor = layer(self.outputs[0])\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/keras/engine/topology.py\", line 511, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/keras/engine/topology.py\", line 569, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/keras/engine/topology.py\", line 150, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/keras/layers/normalization.py\", line 124, in call\n    self.updates = [K.moving_average_update(self.running_mean, mean, self.momentum),\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 288, in moving_average_update\n    variable, value, momentum)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/training/moving_averages.py\", line 70, in assign_moving_average\n    update_delta = _zero_debias(variable, value, decay)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/training/moving_averages.py\", line 177, in _zero_debias\n    trainable=False)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 1024, in get_variable\n    custom_getter=custom_getter)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 850, in get_variable\n    custom_getter=custom_getter)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 346, in get_variable\n    validate_shape=validate_shape)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 331, in _true_getter\n    caching_device=caching_device, validate_shape=validate_shape)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 677, in _get_single_variable\n    expected_shape=shape)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 224, in __init__\n    expected_shape=expected_shape)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 370, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1424, in identity\n    result = _op_def_lib.apply_op(\"Identity\", input=input, name=name)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/deep-learning/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value batchnormalization_1_running_mean/biased\n\t [[Node: batchnormalization_1_running_mean/biased/read = Identity[T=DT_FLOAT, _class=[\"loc:@batchnormalization_1_running_mean\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batchnormalization_1_running_mean/biased)]]\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                    border_mode='valid',\n",
    "                    input_shape=(img_rows, img_cols,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "model.add(Dropout(0.25))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer='sgd',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, \n",
    "          nb_epoch=nb_epoch,verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n",
    "\n",
    "\n",
    "#Evaluating the model on the test data    \n",
    "score, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
